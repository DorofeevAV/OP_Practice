# Подготовка датасета Flowers Recognition

## 1. Источник данных
В проекте используется **Flowers Recognition Dataset** с платформы Kaggle.

Ссылка на датасет:
https://www.kaggle.com/datasets/alxmamaev/flowers-recognition

Идентификатор датасета: `alxmamaev/flowers-recognition`  
Автор: Alexander Mamaev

Датасет содержит изображения **5 классов цветов**:
- daisy
- dandelion
- rose
- sunflower
- tulip

---

## 2. Загрузка датасета
Необходимо скачать датасет **alxmamaev/flowers-recognition** любым удобным способом:
- через веб‑интерфейс Kaggle;
- с использованием Kaggle API.

Ссылка на датасет:
https://www.kaggle.com/datasets/alxmamaev/flowers-recognition

---

## 3. Размещение в проекте
В корне проекта должна находиться папка `data`.

Скачанный архив необходимо **распаковать в папку `data`** так, чтобы **каталоги классов располагались непосредственно в её корне**.

### Правильная структура каталогов:
```
data/
├─ daisy/
├─ dandelion/
├─ rose/
├─ sunflower/
├─ tulip/
```

Если после распаковки появился дополнительный каталог (например, `flowers/`), его содержимое необходимо переместить напрямую в папку `data`.

---

## 4. Требования к данным
- Формат изображений: `.jpg` / `.jpeg`
- Цветовая модель: RGB
- Исходный размер изображений может быть произвольным  
  (приведение к единому размеру выполняется программно)

---

## 5. Предобработка и нормализация данных
Перед обучением нейронной сети изображения проходят стандартную предварительную обработку:
- изменение размера изображений до фиксированного (`128 × 128`);
- преобразование изображений в тензоры PyTorch;
- нормализация значений каналов RGB с использованием коэффициентов ImageNet (mean и std).

Такая схема предобработки является стандартной для задач классификации изображений и обеспечивает более стабильный процесс обучения нейросети.

---

## 6. Архитектура нейронной сети
В проекте реализована **сверточная нейронная сеть (CNN)** с использованием библиотеки **PyTorch**.

Архитектура сети включает:
- сверточные слои для извлечения пространственных признаков изображений;
- функции активации ReLU;
- операции подвыборки (Pooling) для уменьшения размерности признаков;
- слой усреднения признаков;
- полносвязные слои классификатора;
- выходной слой с количеством нейронов, равным числу классов (`5`).

Модель реализована в виде отдельного класса, унаследованного от `torch.nn.Module`, что упрощает модификацию архитектуры и проведение экспериментов.

---

## 7. Обучение нейронной сети
Для обучения модели:
- датасет разделяется на обучающую и тестовую выборки;
- используется функция потерь `CrossEntropyLoss`;
- оптимизация выполняется методом `Adam`;
- обучение проводится в несколько эпох.

В процессе обучения сохраняются значения функции потерь и точности, на основе которых строятся графики обучения.

---

## 8. Оценка качества модели
После завершения обучения проводится оценка нейронной сети на тестовой выборке:
- вычисляется итоговая точность классификации (accuracy);
- строится матрица ошибок (confusion matrix);
- анализируются показатели качества по каждому классу.

Это позволяет оценить адекватность обучения и выявить проблемные классы.

---

## 9. Улучшение архитектуры нейронной сети
После получения базовых результатов была реализована улучшенная версия модели, в которой:
- увеличено количество слоёв;
- изменена конфигурация сверточных блоков;
- скорректированы параметры обучения.

Улучшенная модель была дообучена на тех же данных и повторно протестирована, что позволило добиться прироста точности классификации.

---

## 10. Результаты проекта
В рамках проекта выполнены следующие этапы:
- сбор и подготовка датасета изображений;
- реализация и обучение сверточной нейронной сети;
- оценка качества работы модели;
- улучшение архитектуры и повторное обучение;
- анализ полученных результатов.

Проект демонстрирует полный цикл разработки нейросетевого решения для задачи классификации изображений — от подготовки данных до оценки и улучшения модели.

